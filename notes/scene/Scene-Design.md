

## 场景题：设计判断论文抄袭的系统
1. 一类是基于字符串比较的方法；另一类是基于词频统计的方法。
2. 基于字符串比较的方法也称为数字指纹法，这类方法通过某种选取策略在文档中取一些字符串作为“指纹”，把指纹映射到Hash 表中，最后统计Hash 
3. 表中相同的指纹数目或者比率，作为文本相似度依据。
4. 基于词频统计的方法也称为基于语义的方法。词频统计法源于信息检索技术中的**向量空间模型**，该类方法首先都要统计每篇文档中各个单词的出现次数，然后根据单词频度构成文档特征向量，最后采用点积、余弦或者类似方式度量两篇文档的特征向量，以此作为文档相似度的依据。





## 设计一个即时聊天的系统
1. 用户通过客户端进入系统，向服务器发出消息，请求登陆。
2. 服务器收到请求后，向客户端返回应答消息，表示同意接受该用户加入，并顺带将自己服务线程所在的监听端口号告诉用户。
3. 客户端按照服务器应答中给出的端口号与服务器建立稳定的连接。
4. 服务器通过该连接将当前在线用户的列表信息传给新加入的客户端。
5. 客户端获得了在线用户列表，就可以独立自主地与在线的其他用户通信了。
6. 当用户退出系统时要及时地通知服务器。



## 分布式系统事务一致性解决方案
分布式系统事务一致性解决方案
MQ（事务消息）

举个例子，Bob向Smith转账，那我们到底是先发送消息，还是先执行扣款操作？

好像都可能会出问题。如果先发消息，扣款操作失败，那么Smith的账户里面会多出一笔钱。反过来，如果先执行扣款操作，后发送消息，那有可能扣款成功了但是消息没发出去，Smith收不到钱。除了上面介绍的通过异常捕获和回滚的方式外，还有没有其他的思路呢？

下面以阿里巴巴的RocketMQ中间件为例，分析下其设计和实现思路。

RocketMQ第一阶段发送Prepared消息时，会拿到消息的地址，第二阶段执行本地事物，第三阶段通过第一阶段拿到的地址去访问消息，并修改状态。细心的读者可能又发现问题了，如果确认消息发送失败了怎么办？RocketMQ会定期扫描消息集群中的事物消息，这时候发现了Prepared消息，它会向消息发送者确认，Bob的钱到底是减了还是没减呢？如果减了是回滚还是继续发送确认消息呢？RocketMQ会根据发送端设置的策略来决定是回滚还是继续发送确认消息。这样就保证了消息发送与本地事务同时成功或同时失败。如下图：
![](https://github.com/zaiyunduan123/Java-Interview/blob/master/image/scene-1.jpg)



## 设计高并发的系统？
1. HTML 页面静态化
访问频率较高但内容变动较小，使用网站 HTML 静态化方案来优化访问速度。将社区
内的帖子、文章进行实时的静态化，有更新的时候再重新静态化也是大量使用的策略。
优势：
一、减轻服务器负担。
二、加快页面打开速度， 静态页面无需 访问 数据库，打开速度较动态页面有明显提高；
三、很多搜索引擎都会优先收录静态页面，不仅被收录的快，还收录的全，容易被搜
索引擎找到；
四、HTML 静态页面不会受程序相关漏洞的影响，减少攻击 ，提高安全性。
2. 图片服务器和应用服务器相分离
现在很多的网站上都会用到大量的图片，而图片是网页传输中占主要的数据量,也是影
响网站性能的主要因素。因此很多网站都会将图片存储从网站中分离出来，另外架构一个
或多个服务器来存储图片，将图片放到一个虚拟目录中，而网页上的图片都用一个 URL 地
址来指向这些服务器上的图片的地址，这样的话网站的性能就明显提高了。
优势：
一、分担 Web 服务器的 I/O 负载-将耗费资源的图片服务分离出来，提高服务器的性能
和稳定性。
二、 能够专门对图片服务器进行优化-为图片服务设置有针对性的 缓存方案，减少带宽
成本，提高访问速度。
三、 提高网站的可扩展性-通过增加图片服务器，提高图片吞吐能力。
3. 数据库
见“数据库部分的---如果有一个特别大的访问量到数据库上，怎么做优化？”。
4. 缓存
尽量使用缓存，包括用户缓存，信息缓存等，多花点内存来做缓存，可以大量减少与
数据库的交互，提高性能。
假如我们能减少数据库频繁的访问，那对系统肯定大大有利的。比如一个电子商务系
统的商品搜索，如果某个关键字的商品经常被搜，那就可以考虑这部分商品列表存放到缓
存（内存中去），这样不用每次访问数据库，性能大大增加。
5. 镜像
镜像是冗余的一种类型，一个磁盘上的数据在另一个磁盘上存在一个完全相同的副本
即为镜像。
6. 负载均衡
在网站高并发访问的场景下，使用负载均衡技术（负载均衡服务器）为一个应用构建
一个由多台服务器组成的服务器集群，将并发访问请求分发到多台服务器上处理，避免单
一服务器因负载压力过大而响应缓慢，使用户请求具有更好的响应延迟特性。
7. 并发控制
加锁，如乐观锁和悲观锁。
8. 消息队列
通过 mq 一个一个排队方式，跟 12306 一样。


## 设计高负载的系统
1. 应用无状态
2. 有效使用缓存
3. 应用拆分
4. 数据库拆分
5. 异步通信
6. 非结构化数据存储 ( TFS,NOSQL)
7. 监控、预警系统
8. 配置统一管理



## 订票系统，某车次只有一张火车票，假定有 1w 个人同时打开 12306 网站来订票，如何解决并发问题？（可扩展到任何高并发网站要考虑的 并发读写问题
使用乐观锁，乐观锁意思是不锁定表的情况下，利用业务的控制来解决并发问题，这样既保证数据的并发 可读性 ，又保证保存数据的 排他性，保证性能的同时解决了并发带来
的脏数据问题。hibernate 中实现乐观锁。（乐观锁，使用版本标识来确定读到的数据与提交时的数据是否一致。提交后修改版本标识，不一致时可以采取丢弃和再次尝试的策略。）

## 分布式与集群的区别是什么
分布式：一个业务分拆多个子业务，部署在不同的服务器上
集群：同一个业务，部署在多个服务器上

## 实时展现热门文章，比如近8小时点击量最大的文章前100名
1. 数据接收
- 客户端会为了减轻服务器的压力而选择延迟合并点击请求进行批量发送
- 服务器肯定会有多台机器多进程部署来接受点击请求，接收到的请求在进行参数解析后，被发送到存储单元。为了减轻存储的压力，每个进程可能会使用小窗口聚合数据，每隔一小段时间将窗口内的数据聚合起来一起发给存储单元。
2. 数据存储
- 使用kafka存，ZeroCopy机制并发量很高，数据持久化在磁盘里成本低。不过kafka的数据一般是有过期时间的，如果想完全记住用户的点击以便做长期的数据分析，需要要使用hdfs了
3. 分布式TopN算法
- 用户太多，用户表按用户ID哈希分成了1024张子表。用户表里有一个字段score，表示这个用户的积分数。现在我们要计算前100名积分最多的用户以及积分数，该怎么查询？
- 如果是单个表，一个SQL也就搞定了，
- 如果是多个子表，你得在每个子表上都进行一次TopN查询，然后聚合结果再做一次TopN查询。子表查询可以多线程并行，提高聚合效率。
4. 滑动窗口
- 8小时的滑动窗口，意味着新的数据源源不断的进来，旧的数据时时刻刻在淘汰，在业务可以差几分钟。
- 我们对时间片进行了切分，一分钟一个槽来进行计数，过期了8小时，移掉第一个，计算topn的帖子，维护窗口，移除过期的槽，然后统计topn，30s~60s调用一次
5. 定时任务
- 每个子节点都会有一个定时任务去负责维持统计窗口，过期失效的统计数据，计算局部的topn热帖。
- 现在每个子节点都有了各自的局部topn热帖，那么还需要一个主节点去汇总这些局部热点，然后计算去全局热帖。
6. 点击去重
- 首先要从客户端下手，客户端本身可以过滤一部分无效点击。同一篇文章在太短的时间内被当前用户反复点击，这个模式还是很好发现的。如果间隔时间比较长，那就是读者的回味点击，属于文章的正向反馈，应该记录下来
- 服务器还需要防止用户的防刷行为。如果缺失防刷控制，可以通过这种漏洞来使得自己的文章非法获得大量点击，进入热门文章列表，打上热门标签，被海量的用户看到，就会获得较大的经济效益，即使这篇文章内容本身吸引力并不足够。


## 如何解决电商网站超卖现象
超卖是什么

- 因为数据库底层的写操作和读操作可以同时进行，虽然写操作默认带有隐式锁（即对同一数据不能同时进行写操作）但是读操作默认是不带锁的，所以当用户1去修改库存的时候，用户2依然可以读到库存为1，导致两个用户同时减一次库存，所以出现了超卖现象。

解决方案

1. 使用redis预减库存
2. 当库存大于0，才能更新库存`update sk_goods_seckill set stock_count = stock_count - 1 where goods_id = #{goodsId} and stock_count > 0`
3. 添加唯一索引，UNIQUE KEY `u_uid_gid` (`user_id`,`goods_id`) USING BTREE，防止同一用户同一商品下两次订单
4. 乐观锁，就是在数据库设计一个版本号的字段，每次修改都使其+1，这样在提交时比对提交前的版本号就知道是不是并发提交了，但是有个缺点就是只能是应用中控制，如果有跨应用修改同一条数据乐观锁就没办法了，这个时候可以考虑悲观锁。
5. 悲观锁，就是直接在数据库层面将数据锁死，类似于oralce中使用select xxxxx from xxxx where xx=xx for update，这样其他线程将无法提交数据。
6. 使用消息队列异步下单


## mq异步调用失败，如何保证数据一致性？
1. 按你的使用场景，推送数据必须得在数据创建事务成功之后执行，这里必须有个先后。你可以将推送这个操作异步执行，消息队列有一搬有ack机制，确保消息没丢失。这时候监听消息队列的程序会执行推送，如果推送成功做标记。如果推送失败也标记记录时间，也可以推到另一个消息队列约定多少分钟重试。实在不行就彻底标记失败，或者回滚之前创建的数据。这个才是最终一致性。
2. 如果是并行的操作，就得使用消息队列的confirm机制了。

## 分布式锁的几种实现方式
1. 基于数据库表

- 要实现分布式锁，最简单的方式可能就是直接创建一张锁表，然后通过操作该表中的数据来实现了。

- 我们对method_name（方法名）做了唯一性约束，这里如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，可以执行方法体内容。当方法执行完毕之后，想要释放锁的话就删除该记录

2. 基于数据库排他锁

- 可以通过数据库的排他锁来实现分布式锁
- 在查询语句后面增加for update，数据库会在查询过程中给数据库表增加排他锁（这里再多提一句，InnoDB引擎在加锁的时候，只有通过索引进行检索的时候才会使用行级锁，否则会使用表级锁。这里我们希望使用行级锁，就要给method_name添加索引
- 值得注意的是，这个索引一定要创建成唯一索引，否则会出现多个重载方法之间无法同时被访问的问题。重载方法的话建议把参数类型也加上。）。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。


3. 基于缓存

- 比如Tair的put方法，redis的setnx方法等。并且，这些缓存服务也都提供了对数据的过期自动删除的支持，可以直接设置超时时间来控制锁的释放。

4. 基于Zookeeper

- 每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。

## 消息队列
### 四种MQ区别
![](https://github.com/zaiyunduan123/Java-Interview/blob/master/image/scene-2.jpg)

### 如何保证消息队列是高可用的
1. 集群，以rcoketMQ为例，有多master 模式、多master多slave异步复制模式、多 master多slave同步双写模式。

![](https://github.com/zaiyunduan123/Java-Interview/blob/master/image/scene-3.jpg)
Producer 与 NameServer集群中的其中一个节点（随机选择）建立长连接，定期从 NameServer 获取 Topic 路由信息，并向提供 Topic 服务的 Broker Master 建立长连接，且定时向 Broker 发送心跳。Producer 只能将消息发送到 Broker master，但是 Consumer 则不一样，它同时和提供 Topic 服务的 Master 和 Slave建立长连接，既可以从 Broker Master 订阅消息，也可以从 Broker Slave 订阅消息。

### 如何保证消息不被重复消费
原因：

- 消费者在消费后，会发送一个确认信息给消息队列，消息队列收到后会将该消息从消息队列中删除，例如RabbitMQ是发送一个ACK确认消息，RocketMQ是返回一个CONSUME_SUCCESS成功标志，kafka每一个消息都有一个offset，kafka消费过消息后，需要提交offset，让消息队列知道自己已经消费过了。因为网络传输等等故障，确认信息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将该消息分发给其他的消费者。

解决方法：

1. 消息可以使用唯一id标识
2.  如果拿到这个消息做数据库的insert操作。给这个消息做一个唯一主键，那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。
3. 如果拿到这个消息做redis的set的操作，无论set几次结果都是一样的，set操作是算幂等操作。
4. 使用第三方介质做消费记录。以redis为例，给消息分配一个全局id，只要消费过该消息，将< id,message>以K-V形式写入redis。那消费者开始消费前，先去redis中查询有没消费记录即可。

## 如何防止Cookie被篡改
1. 如果是要防止在传输中被窃取或篡改，请使用 TLS
2. 如果是要防止客户端篡改，请在 cookie 中加入 MAC（消息验证码），比如可以使用 HMAC-SHA256 算法生成。这样，在从cookies得到数据后，再判断一下这个MAC码就可以知道整个cookies字段是否被篡改过。
3. 利用动态密码与Session+Cookies双重验证